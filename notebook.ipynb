{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyek MLOps : Depression Students\n",
    "- **Nama:** Abid Juliant Indraswara\n",
    "- **Email:** abidjuliant@gmail.com\n",
    "- **ID Dicoding:** abidindraswara\n",
    "\n",
    "Fokus pada proyek ini adalah untuk membuat pipeline machine learning dengan topik machine learning yaitu sentimen berita mengenai siswa yang mengalami depresi. Dataset yang digunakan adalah depression-student-dataset yang berasal dari Kaggle.\n",
    "\n",
    "Dataset : https://www.kaggle.com/datasets/ikynahidwin/depression-student-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install & Import Libray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Library Umum\n",
    "import os, shutil\n",
    "from shutil import copyfile\n",
    "import zipfile\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Library untuk Machine Learning dan Pipeline\n",
    "import tensorflow as tf\n",
    "import tensorflow_model_analysis as tfma\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tfx.components import (\n",
    "    CsvExampleGen,\n",
    "    StatisticsGen,\n",
    "    SchemaGen,\n",
    "    ExampleValidator,\n",
    "    Transform,\n",
    "    Trainer,\n",
    "    Evaluator,\n",
    "    Pusher,\n",
    "    Tuner\n",
    ")\n",
    "from tfx.proto import example_gen_pb2, trainer_pb2, pusher_pb2\n",
    "from tfx.types import Channel\n",
    "from tfx.dsl.components.common.resolver import Resolver\n",
    "from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext\n",
    "from tfx.types.standard_artifacts import Model, ModelBlessing\n",
    "from tfx.dsl.input_resolution.strategies.latest_blessed_model_strategy import (\n",
    "    LatestBlessedModelStrategy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading & Cek Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Academic Pressure</th>\n",
       "      <th>Study Satisfaction</th>\n",
       "      <th>Sleep Duration</th>\n",
       "      <th>Dietary Habits</th>\n",
       "      <th>Have you ever had suicidal thoughts ?</th>\n",
       "      <th>Study Hours</th>\n",
       "      <th>Financial Stress</th>\n",
       "      <th>Family History of Mental Illness</th>\n",
       "      <th>Depression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>28</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7-8 hours</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>28</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5-6 hours</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>Yes</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5-6 hours</td>\n",
       "      <td>Unhealthy</td>\n",
       "      <td>Yes</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>More than 8 hours</td>\n",
       "      <td>Unhealthy</td>\n",
       "      <td>Yes</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Female</td>\n",
       "      <td>31</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>More than 8 hours</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>Male</td>\n",
       "      <td>26</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>More than 8 hours</td>\n",
       "      <td>Unhealthy</td>\n",
       "      <td>No</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>Male</td>\n",
       "      <td>24</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Less than 5 hours</td>\n",
       "      <td>Unhealthy</td>\n",
       "      <td>Yes</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>Female</td>\n",
       "      <td>23</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5-6 hours</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>Male</td>\n",
       "      <td>33</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>More than 8 hours</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>No</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>Male</td>\n",
       "      <td>18</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>More than 8 hours</td>\n",
       "      <td>Unhealthy</td>\n",
       "      <td>No</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>502 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Gender  Age  Academic Pressure  Study Satisfaction     Sleep Duration  \\\n",
       "0      Male   28                2.0                 4.0          7-8 hours   \n",
       "1      Male   28                4.0                 5.0          5-6 hours   \n",
       "2      Male   25                1.0                 3.0          5-6 hours   \n",
       "3      Male   23                1.0                 4.0  More than 8 hours   \n",
       "4    Female   31                1.0                 5.0  More than 8 hours   \n",
       "..      ...  ...                ...                 ...                ...   \n",
       "497    Male   26                5.0                 2.0  More than 8 hours   \n",
       "498    Male   24                2.0                 1.0  Less than 5 hours   \n",
       "499  Female   23                3.0                 5.0          5-6 hours   \n",
       "500    Male   33                4.0                 4.0  More than 8 hours   \n",
       "501    Male   18                5.0                 3.0  More than 8 hours   \n",
       "\n",
       "    Dietary Habits Have you ever had suicidal thoughts ?  Study Hours  \\\n",
       "0         Moderate                                   Yes            9   \n",
       "1          Healthy                                   Yes            7   \n",
       "2        Unhealthy                                   Yes           10   \n",
       "3        Unhealthy                                   Yes            7   \n",
       "4          Healthy                                   Yes            4   \n",
       "..             ...                                   ...          ...   \n",
       "497      Unhealthy                                    No            8   \n",
       "498      Unhealthy                                   Yes            8   \n",
       "499        Healthy                                    No            1   \n",
       "500        Healthy                                    No            8   \n",
       "501      Unhealthy                                    No            6   \n",
       "\n",
       "     Financial Stress Family History of Mental Illness Depression  \n",
       "0                   2                              Yes         No  \n",
       "1                   1                              Yes         No  \n",
       "2                   4                               No        Yes  \n",
       "3                   2                              Yes         No  \n",
       "4                   2                              Yes         No  \n",
       "..                ...                              ...        ...  \n",
       "497                 3                               No        Yes  \n",
       "498                 5                               No        Yes  \n",
       "499                 5                              Yes         No  \n",
       "500                 1                              Yes         No  \n",
       "501                 2                              Yes        Yes  \n",
       "\n",
       "[502 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset Depression Students\n",
    "depression_df = pd.read_csv(\"./depression_student/data/data.csv\")\n",
    "depression_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cek Nilai NaN Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cek NaN Dataset Depression Student\n",
      "Gender                                   0\n",
      "Age                                      0\n",
      "Academic Pressure                        0\n",
      "Study Satisfaction                       0\n",
      "Sleep Duration                           0\n",
      "Dietary Habits                           0\n",
      "Have you ever had suicidal thoughts ?    0\n",
      "Study Hours                              0\n",
      "Financial Stress                         0\n",
      "Family History of Mental Illness         0\n",
      "Depression                               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cek NaN Dataset\n",
    "print('Cek NaN Dataset Depression Student')\n",
    "print(depression_df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cek Info Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 502 entries, 0 to 501\n",
      "Data columns (total 11 columns):\n",
      " #   Column                                 Non-Null Count  Dtype  \n",
      "---  ------                                 --------------  -----  \n",
      " 0   Gender                                 502 non-null    object \n",
      " 1   Age                                    502 non-null    int64  \n",
      " 2   Academic Pressure                      502 non-null    float64\n",
      " 3   Study Satisfaction                     502 non-null    float64\n",
      " 4   Sleep Duration                         502 non-null    object \n",
      " 5   Dietary Habits                         502 non-null    object \n",
      " 6   Have you ever had suicidal thoughts ?  502 non-null    object \n",
      " 7   Study Hours                            502 non-null    int64  \n",
      " 8   Financial Stress                       502 non-null    int64  \n",
      " 9   Family History of Mental Illness       502 non-null    object \n",
      " 10  Depression                             502 non-null    object \n",
      "dtypes: float64(2), int64(3), object(6)\n",
      "memory usage: 43.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# Cek Info Dataset\n",
    "depression_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cek Fitur Kategori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cek Kategori untuk Kolom dengan Tipe Data object\n",
    "category_per_columns = depression_df.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender: \n",
      "['Male' 'Female'] \n",
      "\n",
      "Sleep Duration: \n",
      "['7-8 hours' '5-6 hours' 'More than 8 hours' 'Less than 5 hours'] \n",
      "\n",
      "Dietary Habits: \n",
      "['Moderate' 'Healthy' 'Unhealthy'] \n",
      "\n",
      "Have you ever had suicidal thoughts ?: \n",
      "['Yes' 'No'] \n",
      "\n",
      "Family History of Mental Illness: \n",
      "['Yes' 'No'] \n",
      "\n",
      "Depression: \n",
      "['No' 'Yes'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cek per Parameter atau kolom\n",
    "for column in category_per_columns:\n",
    "    category_value = depression_df[column].unique()\n",
    "    print(f\"{column}: \\n{category_value}\", '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Depression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>502 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Depression\n",
       "0             0\n",
       "1             0\n",
       "2             1\n",
       "3             0\n",
       "4             0\n",
       "..          ...\n",
       "497           1\n",
       "498           1\n",
       "499           0\n",
       "500           0\n",
       "501           1\n",
       "\n",
       "[502 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inisialisasi LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Mengonversi kolom 'Depression' menjadi label numerik\n",
    "depression_df['Depression'] = label_encoder.fit_transform(depression_df['Depression'])\n",
    "\n",
    "# Tampilkan hasil label encoding\n",
    "depression_df[['Depression']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Dataset File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dataset to csv file\n",
    "depression_df.to_csv(\"./data/data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Pipeline Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Library TFX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tfx.orchestration.beam.beam_dag_runner import BeamDagRunner\n",
    "from modules.pipeline import init_local_pipeline\n",
    "from modules.depression_components import init_components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init Variabel Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_NAME = 'abidindraswara-pipeline'\n",
    "\n",
    "DATA_ROOT = 'data'\n",
    "TRANSFORM_MODULE_FILE = 'modules/depression_transform.py'\n",
    "TRAINER_MODULE_FILE = 'modules/depression_trainer.py'\n",
    "\n",
    "OUTPUT_BASE = 'output'\n",
    "serving_model_dir = os.path.join(OUTPUT_BASE, 'serving_model')\n",
    "pipeline_root = os.path.join(OUTPUT_BASE, PIPELINE_NAME)\n",
    "metadata_path = os.path.join(pipeline_root, 'metadata.sqlite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Pipeline secara Lokal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.runners.interactive.interactive_environment:Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n        if (typeof window.interactive_beam_jquery == 'undefined') {\n          var jqueryScript = document.createElement('script');\n          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n          jqueryScript.type = 'text/javascript';\n          jqueryScript.onload = function() {\n            var datatableScript = document.createElement('script');\n            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n            datatableScript.type = 'text/javascript';\n            datatableScript.onload = function() {\n              window.interactive_beam_jquery = jQuery.noConflict(true);\n              window.interactive_beam_jquery(document).ready(function($){\n                \n              });\n            }\n            document.head.appendChild(datatableScript);\n          };\n          document.head.appendChild(jqueryScript);\n        } else {\n          window.interactive_beam_jquery(document).ready(function($){\n            \n          });\n        }"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734165892   nanos: 984161853 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\apache_beam\\\\runners\\\\worker\\\\sdk_worker_main.py:339\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734165892   nanos: 992477655 } message: \"Discarding unparseable args: [\\'--direct_runner_use_stacked_bundle\\', \\'--pipeline_type_check\\']\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\apache_beam\\\\options\\\\pipeline_options.py:356\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734165892   nanos: 989860296 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\apache_beam\\\\runners\\\\worker\\\\sdk_worker_main.py:339\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734165892   nanos: 998813152 } message: \"Discarding unparseable args: [\\'--direct_runner_use_stacked_bundle\\', \\'--pipeline_type_check\\']\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\apache_beam\\\\options\\\\pipeline_options.py:356\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734165893   nanos: 43316364 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\apache_beam\\\\runners\\\\worker\\\\sdk_worker_main.py:339\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734165893   nanos: 52173852 } message: \"Discarding unparseable args: [\\'--direct_runner_use_stacked_bundle\\', \\'--pipeline_type_check\\']\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\apache_beam\\\\options\\\\pipeline_options.py:356\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734165893   nanos: 243715047 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\apache_beam\\\\runners\\\\worker\\\\sdk_worker_main.py:339\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734165893   nanos: 253695487 } message: \"Discarding unparseable args: [\\'--direct_runner_use_stacked_bundle\\', \\'--pipeline_type_check\\']\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\apache_beam\\\\options\\\\pipeline_options.py:356\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734165909   nanos: 901276588 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_26\" transform_id: \"WriteSplit[train]/Write/Write/WriteImpl/WriteBundles\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\apache_beam\\\\io\\\\tfrecordio.py:59\" thread: \"Thread-13\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734165909   nanos: 901276588 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_27\" transform_id: \"WriteSplit[train]/Write/Write/WriteImpl/WriteBundles\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\apache_beam\\\\io\\\\tfrecordio.py:59\" thread: \"Thread-12\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734165909   nanos: 901276588 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_29\" transform_id: \"WriteSplit[train]/Write/Write/WriteImpl/WriteBundles\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\apache_beam\\\\io\\\\tfrecordio.py:59\" thread: \"Thread-12\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734165909   nanos: 965297698 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_28\" transform_id: \"WriteSplit[train]/Write/Write/WriteImpl/WriteBundles\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\apache_beam\\\\io\\\\tfrecordio.py:59\" thread: \"Thread-13\" \n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734165947   nanos: 786729097 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\apache_beam\\\\runners\\\\worker\\\\sdk_worker_main.py:339\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734165947   nanos: 795858621 } message: \"Discarding unparseable args: [\\'--direct_runner_use_stacked_bundle\\', \\'--pipeline_type_check\\']\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\apache_beam\\\\options\\\\pipeline_options.py:356\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734165947   nanos: 809752464 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\apache_beam\\\\runners\\\\worker\\\\sdk_worker_main.py:339\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734165947   nanos: 823233127 } message: \"Discarding unparseable args: [\\'--direct_runner_use_stacked_bundle\\', \\'--pipeline_type_check\\']\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\apache_beam\\\\options\\\\pipeline_options.py:356\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734165947   nanos: 914147377 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\apache_beam\\\\runners\\\\worker\\\\sdk_worker_main.py:339\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734165947   nanos: 926462650 } message: \"Discarding unparseable args: [\\'--direct_runner_use_stacked_bundle\\', \\'--pipeline_type_check\\']\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\apache_beam\\\\options\\\\pipeline_options.py:356\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734165947   nanos: 937959671 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\apache_beam\\\\runners\\\\worker\\\\sdk_worker_main.py:339\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734165947   nanos: 950761556 } message: \"Discarding unparseable args: [\\'--direct_runner_use_stacked_bundle\\', \\'--pipeline_type_check\\']\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\apache_beam\\\\options\\\\pipeline_options.py:356\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734165958   nanos: 271736621 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_84\" transform_id: \"TFXIORead[train]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\apache_beam\\\\io\\\\tfrecordio.py:59\" thread: \"Thread-12\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734165958   nanos: 285864353 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_83\" transform_id: \"TFXIORead[train]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\apache_beam\\\\io\\\\tfrecordio.py:59\" thread: \"Thread-12\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734165958   nanos: 291082143 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_85\" transform_id: \"TFXIORead[train]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\apache_beam\\\\io\\\\tfrecordio.py:59\" thread: \"Thread-11\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734165958   nanos: 307350635 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_86\" transform_id: \"TFXIORead[train]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\apache_beam\\\\io\\\\tfrecordio.py:59\" thread: \"Thread-12\" \n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Users\\Lenovo\\anaconda3\\envs\\mlops-tfx-2\\lib\\site-packages\\tensorflow_transform\\tf_utils.py:325: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use ref() instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Users\\Lenovo\\anaconda3\\envs\\mlops-tfx-2\\lib\\site-packages\\tensorflow_transform\\tf_utils.py:325: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use ref() instead.\n",
      "WARNING:root:This output type hint will be ignored and not used for type-checking purposes. Typically, output type hints for a PTransform are single (or nested) types wrapped by a PCollection, PDone, or None. Got: Tuple[Dict[<class 'str'>, Union[<class 'NoneType'>, <class 'tfx.components.transform.executor._Dataset'>]], Union[<class 'NoneType'>, Dict[<class 'str'>, Dict[<class 'str'>, <class 'apache_beam.pvalue.PCollection'>]]], <class 'int'>] instead.\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_1/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_2/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_3/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_4/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_1/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_2/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_3/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_4/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:root:This output type hint will be ignored and not used for type-checking purposes. Typically, output type hints for a PTransform are single (or nested) types wrapped by a PCollection, PDone, or None. Got: Tuple[Dict[<class 'str'>, Union[<class 'NoneType'>, <class 'tfx.components.transform.executor._Dataset'>]], Union[<class 'NoneType'>, Dict[<class 'str'>, Dict[<class 'str'>, <class 'apache_beam.pvalue.PCollection'>]]], <class 'int'>] instead.\n",
      "WARNING:root:This input type hint will be ignored and not used for type-checking purposes. Typically, input type hints for a PTransform are single (or nested) types wrapped by a PCollection, or PBegin. Got: Dict[<class 'tensorflow_transform.beam.analyzer_cache.DatasetKey'>, <class 'tensorflow_transform.beam.analyzer_cache.DatasetCache'>] instead.\n",
      "WARNING:root:This output type hint will be ignored and not used for type-checking purposes. Typically, output type hints for a PTransform are single (or nested) types wrapped by a PCollection, PDone, or None. Got: List[<class 'apache_beam.pvalue.PDone'>] instead.\n",
      "WARNING:root:This input type hint will be ignored and not used for type-checking purposes. Typically, input type hints for a PTransform are single (or nested) types wrapped by a PCollection, or PBegin. Got: Dict[<class 'tensorflow_transform.beam.analyzer_cache.DatasetKey'>, <class 'tensorflow_transform.beam.analyzer_cache.DatasetCache'>] instead.\n",
      "WARNING:root:This output type hint will be ignored and not used for type-checking purposes. Typically, output type hints for a PTransform are single (or nested) types wrapped by a PCollection, PDone, or None. Got: List[<class 'apache_beam.pvalue.PDone'>] instead.\n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734166019   nanos: 856645107 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\apache_beam\\\\runners\\\\worker\\\\sdk_worker_main.py:339\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734166019   nanos: 866313457 } message: \"Discarding unparseable args: [\\'--pipeline_type_check\\', \\'--direct_runner_use_stacked_bundle\\']\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\apache_beam\\\\options\\\\pipeline_options.py:356\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734166019   nanos: 854739904 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\apache_beam\\\\runners\\\\worker\\\\sdk_worker_main.py:339\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734166019   nanos: 868313550 } message: \"Discarding unparseable args: [\\'--pipeline_type_check\\', \\'--direct_runner_use_stacked_bundle\\']\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\apache_beam\\\\options\\\\pipeline_options.py:356\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734166019   nanos: 952310562 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\apache_beam\\\\runners\\\\worker\\\\sdk_worker_main.py:339\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734166019   nanos: 966246843 } message: \"Discarding unparseable args: [\\'--pipeline_type_check\\', \\'--direct_runner_use_stacked_bundle\\']\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\apache_beam\\\\options\\\\pipeline_options.py:356\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734166020   nanos: 82825899 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\apache_beam\\\\runners\\\\worker\\\\sdk_worker_main.py:339\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734166020   nanos: 92366933 } message: \"Discarding unparseable args: [\\'--pipeline_type_check\\', \\'--direct_runner_use_stacked_bundle\\']\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\apache_beam\\\\options\\\\pipeline_options.py:356\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734166028   nanos: 858404397 } message: \"From d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\tensorflow_transform\\\\tf_utils.py:325: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\\nInstructions for updating:\\nUse ref() instead.\" instruction_id: \"bundle_254\" transform_id: \"Analyze/CreateSavedModelForAnalyzerInputs[Phase0][tf_v2_only]/CreateSavedModel\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\util\\\\deprecation.py:350\" thread: \"Thread-12\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734166047   nanos: 649533510 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_450\" transform_id: \"TFXIOReadAndDecode[AnalysisIndex0]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\apache_beam\\\\io\\\\tfrecordio.py:59\" thread: \"Thread-12\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734166047   nanos: 680518865 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_451\" transform_id: \"TFXIOReadAndDecode[AnalysisIndex0]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\apache_beam\\\\io\\\\tfrecordio.py:59\" thread: \"Thread-12\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734166047   nanos: 683527946 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_453\" transform_id: \"TFXIOReadAndDecode[AnalysisIndex0]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\apache_beam\\\\io\\\\tfrecordio.py:59\" thread: \"Thread-12\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734166047   nanos: 755755662 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_452\" transform_id: \"TFXIOReadAndDecode[AnalysisIndex0]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\apache_beam\\\\io\\\\tfrecordio.py:59\" thread: \"Thread-13\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734166068   nanos: 619329214 } message: \"From d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\tensorflow_transform\\\\tf_utils.py:325: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\\nInstructions for updating:\\nUse ref() instead.\" instruction_id: \"bundle_955\" transform_id: \"Analyze/CreateSavedModel[tf_v2_only]/CreateSavedModel\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\util\\\\deprecation.py:350\" thread: \"Thread-12\" \n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
      "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
      "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Gender_xf (InputLayer)         [(None, 3)]          0           []                               \n",
      "                                                                                                  \n",
      " SleepDuration_xf (InputLayer)  [(None, 5)]          0           []                               \n",
      "                                                                                                  \n",
      " DietaryHabits_xf (InputLayer)  [(None, 4)]          0           []                               \n",
      "                                                                                                  \n",
      " Haveyoueverhadsuicidalthoughts  [(None, 3)]         0           []                               \n",
      " _xf (InputLayer)                                                                                 \n",
      "                                                                                                  \n",
      " FamilyHistoryofMentalIllness_x  [(None, 3)]         0           []                               \n",
      " f (InputLayer)                                                                                   \n",
      "                                                                                                  \n",
      " Age_xf (InputLayer)            [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " AcademicPressure_xf (InputLaye  [(None, 1)]         0           []                               \n",
      " r)                                                                                               \n",
      "                                                                                                  \n",
      " StudySatisfaction_xf (InputLay  [(None, 1)]         0           []                               \n",
      " er)                                                                                              \n",
      "                                                                                                  \n",
      " StudyHours_xf (InputLayer)     [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " FinancialStress_xf (InputLayer  [(None, 1)]         0           []                               \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 23)           0           ['Gender_xf[0][0]',              \n",
      "                                                                  'SleepDuration_xf[0][0]',       \n",
      "                                                                  'DietaryHabits_xf[0][0]',       \n",
      "                                                                  'Haveyoueverhadsuicidalthoughts_\n",
      "                                                                 xf[0][0]',                       \n",
      "                                                                  'FamilyHistoryofMentalIllness_xf\n",
      "                                                                 [0][0]',                         \n",
      "                                                                  'Age_xf[0][0]',                 \n",
      "                                                                  'AcademicPressure_xf[0][0]',    \n",
      "                                                                  'StudySatisfaction_xf[0][0]',   \n",
      "                                                                  'StudyHours_xf[0][0]',          \n",
      "                                                                  'FinancialStress_xf[0][0]']     \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 256)          6144        ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 64)           16448       ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 16)           1040        ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 1)            17          ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,649\n",
      "Trainable params: 23,649\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/5\n",
      "5000/5000 [==============================] - 18s 3ms/step - loss: 0.0055 - binary_accuracy: 0.9984 - val_loss: 0.1630 - val_binary_accuracy: 0.9651\n",
      "Epoch 2/5\n",
      "5000/5000 [==============================] - 16s 3ms/step - loss: 6.1512e-07 - binary_accuracy: 1.0000 - val_loss: 0.2017 - val_binary_accuracy: 0.9651\n",
      "Epoch 3/5\n",
      "5000/5000 [==============================] - 16s 3ms/step - loss: 3.3622e-08 - binary_accuracy: 1.0000 - val_loss: 0.2253 - val_binary_accuracy: 0.9535\n",
      "Epoch 4/5\n",
      "5000/5000 [==============================] - 16s 3ms/step - loss: 4.0441e-09 - binary_accuracy: 1.0000 - val_loss: 0.2515 - val_binary_accuracy: 0.9535\n",
      "Epoch 5/5\n",
      "5000/5000 [==============================] - 16s 3ms/step - loss: 2.2202e-09 - binary_accuracy: 1.0000 - val_loss: 0.2666 - val_binary_accuracy: 0.9419\n",
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: output\\abidindraswara-pipeline\\Trainer\\model\\7\\Format-Serving\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: output\\abidindraswara-pipeline\\Trainer\\model\\7\\Format-Serving\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000223EC097EE0> and <keras.engine.input_layer.InputLayer object at 0x00000223EAC359A0>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000223EC097EE0> and <keras.engine.input_layer.InputLayer object at 0x00000223EAC359A0>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000223EAC1F970> and <keras.engine.input_layer.InputLayer object at 0x00000223EE2445E0>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000223EAC1F970> and <keras.engine.input_layer.InputLayer object at 0x00000223EE2445E0>).\n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734166217   nanos: 958788871 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\apache_beam\\\\runners\\\\worker\\\\sdk_worker_main.py:339\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734166217   nanos: 963828802 } message: \"Discarding unparseable args: [\\'--pipeline_type_check\\', \\'--direct_runner_use_stacked_bundle\\']\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\apache_beam\\\\options\\\\pipeline_options.py:356\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734166217   nanos: 958788871 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\apache_beam\\\\runners\\\\worker\\\\sdk_worker_main.py:339\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734166217   nanos: 969417572 } message: \"Discarding unparseable args: [\\'--pipeline_type_check\\', \\'--direct_runner_use_stacked_bundle\\']\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\apache_beam\\\\options\\\\pipeline_options.py:356\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734166217   nanos: 980230093 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\apache_beam\\\\runners\\\\worker\\\\sdk_worker_main.py:339\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734166217   nanos: 990202903 } message: \"Discarding unparseable args: [\\'--pipeline_type_check\\', \\'--direct_runner_use_stacked_bundle\\']\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\apache_beam\\\\options\\\\pipeline_options.py:356\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734166218   nanos: 126505136 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\apache_beam\\\\runners\\\\worker\\\\sdk_worker_main.py:339\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734166218   nanos: 134075164 } message: \"Discarding unparseable args: [\\'--pipeline_type_check\\', \\'--direct_runner_use_stacked_bundle\\']\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\apache_beam\\\\options\\\\pipeline_options.py:356\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734166235   nanos: 162180185 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000020AB521A8E0> and <keras.engine.input_layer.InputLayer object at 0x0000020AB508DEE0>).\" instruction_id: \"bundle_1150\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-11\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734166235   nanos: 162180185 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x000002DE5C68EFA0> and <keras.engine.input_layer.InputLayer object at 0x000002DE5C4E5AF0>).\" instruction_id: \"bundle_1149\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-12\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734166235   nanos: 215987205 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000258E69DFEE0> and <keras.engine.input_layer.InputLayer object at 0x00000258E68C9A30>).\" instruction_id: \"bundle_1151\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-12\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734166235   nanos: 314264297 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000219CC1BC370> and <keras.engine.input_layer.InputLayer object at 0x00000219CC031EE0>).\" instruction_id: \"bundle_1148\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-11\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734166238   nanos: 169705152 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x000002DE5FB79B20> and <keras.engine.input_layer.InputLayer object at 0x000002DE5FBFB460>).\" instruction_id: \"bundle_1149\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-12\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734166238   nanos: 227322101 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000020AB8709550> and <keras.engine.input_layer.InputLayer object at 0x0000020AB8683100>).\" instruction_id: \"bundle_1150\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-11\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734166238   nanos: 326036930 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000258E9F3AAC0> and <keras.engine.input_layer.InputLayer object at 0x00000258E9FBC3A0>).\" instruction_id: \"bundle_1151\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-12\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734166238   nanos: 430332660 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000219CE6A1F10> and <keras.engine.input_layer.InputLayer object at 0x00000219CE724820>).\" instruction_id: \"bundle_1148\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-11\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734166238   nanos: 678941488 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_1149\" transform_id: \"ReadFromTFRecordToArrow[eval][0]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\apache_beam\\\\io\\\\tfrecordio.py:59\" thread: \"Thread-12\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734166238   nanos: 678941488 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_1150\" transform_id: \"ReadFromTFRecordToArrow[eval][0]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\apache_beam\\\\io\\\\tfrecordio.py:59\" thread: \"Thread-11\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734166238   nanos: 766398906 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_1151\" transform_id: \"ReadFromTFRecordToArrow[eval][0]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\apache_beam\\\\io\\\\tfrecordio.py:59\" thread: \"Thread-12\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734166238   nanos: 838185548 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_1148\" transform_id: \"ReadFromTFRecordToArrow[eval][0]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\apache_beam\\\\io\\\\tfrecordio.py:59\" thread: \"Thread-11\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734166240   nanos: 901856422 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000219D3C33CA0> and <keras.engine.input_layer.InputLayer object at 0x00000219D3C0DEE0>).\" instruction_id: \"bundle_1172\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-11\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734166240   nanos: 948974132 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x000002DE6510B9A0> and <keras.engine.input_layer.InputLayer object at 0x000002DE650E4580>).\" instruction_id: \"bundle_1173\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-12\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734166240   nanos: 964612722 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000258EF4CA700> and <keras.engine.input_layer.InputLayer object at 0x00000258EF4A1EB0>).\" instruction_id: \"bundle_1175\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-12\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734166240   nanos: 987377405 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000020ABDCA1370> and <keras.engine.input_layer.InputLayer object at 0x0000020ABDC7EFD0>).\" instruction_id: \"bundle_1174\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-11\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734166242   nanos: 963860273 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000219D6029F10> and <keras.engine.input_layer.InputLayer object at 0x00000219D3C0E7C0>).\" instruction_id: \"bundle_1172\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-11\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734166243   nanos: 12238025 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000258F1A0D970> and <keras.engine.input_layer.InputLayer object at 0x00000258EF4A6280>).\" instruction_id: \"bundle_1175\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-12\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734166243   nanos: 108437776 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x000002DE6764AC10> and <keras.engine.input_layer.InputLayer object at 0x000002DE650FBFD0>).\" instruction_id: \"bundle_1173\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-12\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734166243   nanos: 206233739 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000020AC00905E0> and <keras.engine.input_layer.InputLayer object at 0x0000020ABDC7F460>).\" instruction_id: \"bundle_1174\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-11\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734166245   nanos: 323692321 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000258F3D285E0> and <keras.engine.input_layer.InputLayer object at 0x00000258F3CF23A0>).\" instruction_id: \"bundle_1187\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-12\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734166245   nanos: 340371131 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x000002DE69967880> and <keras.engine.input_layer.InputLayer object at 0x000002DE69932640>).\" instruction_id: \"bundle_1185\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-12\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734166245   nanos: 407127618 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000020AC162AA90> and <keras.engine.input_layer.InputLayer object at 0x0000020AC14F9CA0>).\" instruction_id: \"bundle_1186\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-11\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734166245   nanos: 433396816 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000219D84ABAC0> and <keras.engine.input_layer.InputLayer object at 0x00000219D84796A0>).\" instruction_id: \"bundle_1184\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-11\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734166247   nanos: 933709859 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x000002DE6AE4DE20> and <keras.engine.input_layer.InputLayer object at 0x000002DE6AE25D60>).\" instruction_id: \"bundle_1197\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-12\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734166247   nanos: 953866481 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000020AC4A91D90> and <keras.engine.input_layer.InputLayer object at 0x0000020AC39CBCD0>).\" instruction_id: \"bundle_1198\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-11\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734166247   nanos: 958877325 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000258F520DD90> and <keras.engine.input_layer.InputLayer object at 0x00000258F51E7CD0>).\" instruction_id: \"bundle_1199\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-12\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734166247   nanos: 953866481 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000219DAA389D0> and <keras.engine.input_layer.InputLayer object at 0x00000219D99D0DF0>).\" instruction_id: \"bundle_1196\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-11\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734166249   nanos: 868868827 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x000002DE6E3345E0> and <keras.engine.input_layer.InputLayer object at 0x000002DE6D2E2880>).\" instruction_id: \"bundle_1197\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-12\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734166249   nanos: 884153127 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000219DBEA1190> and <keras.engine.input_layer.InputLayer object at 0x00000219D9A36F70>).\" instruction_id: \"bundle_1196\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-11\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734166249   nanos: 922368049 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000020AC5EF8550> and <keras.engine.input_layer.InputLayer object at 0x0000020AC39DBDF0>).\" instruction_id: \"bundle_1198\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-11\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1734166249   nanos: 946645498 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000258F86E3550> and <keras.engine.input_layer.InputLayer object at 0x00000258F51F8DF0>).\" instruction_id: \"bundle_1199\" log_location: \"d:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-tfx-2\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-12\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Users\\Lenovo\\anaconda3\\envs\\mlops-tfx-2\\lib\\site-packages\\tensorflow_model_analysis\\writers\\metrics_plots_and_validations_writer.py:110: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Users\\Lenovo\\anaconda3\\envs\\mlops-tfx-2\\lib\\site-packages\\tensorflow_model_analysis\\writers\\metrics_plots_and_validations_writer.py:110: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n"
     ]
    }
   ],
   "source": [
    "components = init_components(\n",
    "    data_dir=DATA_ROOT,\n",
    "    transform_module=TRANSFORM_MODULE_FILE,\n",
    "    training_module=TRAINER_MODULE_FILE,\n",
    "    training_steps=5000,\n",
    "    eval_steps=1000,\n",
    "    serving_model_dir=serving_model_dir\n",
    ")\n",
    "\n",
    "pipeline = init_local_pipeline(components, pipeline_root)\n",
    "BeamDagRunner().run(pipeline)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops-tfx-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
